{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is used to predict the real-valued output y based on the given input value x. \n",
    "# It depicts the relationship between the dependent variable y and the independent variables xi  ( or features ). \n",
    "# The hypothetical function used for prediction is represented by h( x ).\n",
    "\n",
    "# h( x ) = w * x + b  \n",
    "    \n",
    " # here, b is the bias.\n",
    " # x represents the feature vector\n",
    " # w represents the weight vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear regression with one variable is also called univariant linear regression.  After initializing the \n",
    "# weight vector, we can find the weight vector to best fit the model by ordinary least squares method or\n",
    "#  gradient descent learning.\n",
    "\n",
    "# Mathematical Intuition: The cost function (or loss function) is used to measure the performance of a machine\n",
    "# learning model or quantifies the error between the expected values and the values predicted by our \n",
    "# hypothetical function.The cost function for Linear Regression is represented by J.\n",
    "\n",
    "        #    J = (1/2m)*(h(x[i])-y(i))^2\n",
    "\n",
    "# Here, m is the total number of training examples in the dataset.\n",
    "# y(i) represents the value of target variable for ith training example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu,std = [],[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(x,y):\n",
    "    plt.xlabel('Independant Variable Name')\n",
    "    plt.ylabel('Dependant Variable Name')\n",
    "    plt.plot(x[:,0],y,'bo')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z = (x - mu)/sigma\n",
    "# x - data\n",
    "# mu - mean.\n",
    "# sigma - standard deviation.\n",
    "def normalize(data):\n",
    "    for i in range(0,data.shape[1]-1):\n",
    "        data[:,i] = ((data[:,i] - np.mean(data[:,i])))/np.std(data[:,i])\n",
    "        mu.append(np.mean(data[:,i]))\n",
    "        std.append(np.std(data[:, i]))\n",
    "\n",
    "    # The code goes through all the columns in the dataframe and normalizes the data with the mean and \n",
    "# standard deviation of each column data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import index\n",
    "\n",
    "\n",
    "def load_data(filename):\n",
    "    df = pd.read_csv(filename,sep=',',index_col=False)\n",
    "    df.columns = ['house_size','rooms','price'] # Columns Name to be added from the data.\n",
    "    data = np.array(df,dtype=np.float32)\n",
    "    plot_data(data[:,:2],data[:,-1])\n",
    "    normalize(data)\n",
    "    return data[:,:2],data[:,-1] # independant and dependant variables data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First of all we need to define what our hypothesis function looks like because we will be using this\n",
    "#  hypothesis for calculating the cost later on. We know for linear regression our hypothesis is:\n",
    "\n",
    "# hθ(x) = θ0 + θ1x1 + θ2x2 + θ3x3 +…..+ θnxn\n",
    "\n",
    "# Our dataset however has only 2 features, so for our current problem the hypothesis is:\n",
    "\n",
    "# hθ(x) = θ0 + θ1x1 + θ2x2\n",
    "\n",
    "# where x1 and x2 are the two features (i.e. size of house and number of rooms). Lets put this in a simple\n",
    "#  python function which returns the hypothesis:\n",
    "\n",
    "def h(x,theta):\n",
    "    return np.matmul(x,theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#    J = (1/2m)*(h(x[i])-y(i))^2\n",
    "def cost_function(x,y,theta):\n",
    "    return ((h(x,theta)-y).T@(h(x,theta)-y))/(2*y.shape[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we have the cost we must minimize it and for that we use… yes gradient descent indeed!\n",
    "# Gradient descent in our context is an optimization algorithm that aims to adjust the parameters in order to minimize the cost function .\n",
    "\n",
    "# The main update step for gradient descent is:\n",
    "            # theta(j) := theta(j) - alpha*Der/Der[theta(j)](J(theta0,theta1))    (For j=0 and j=1)\n",
    "\n",
    "# So we multiply the derivative of the cost function with the learning rate(α) and subtract it from the present\n",
    "# value of the parameters(θ) to get the new updated parameters(θ).\n",
    "\n",
    "def gradient_descent(x,y,theta,learning_rate=0.1,no_epochs=10):\n",
    "        m = x.shape[0]\n",
    "        J_all = []\n",
    "        for _ in range(no_epochs):\n",
    "            h_x = h(x,theta)\n",
    "            cost = (1/m)*(x.T@(h_x-y))\n",
    "            theta = theta - learning_rate*cost\n",
    "            J_all.append(cost_function(x,y,theta))\n",
    "        return theta,J_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cost(J_all, num_epochs):\n",
    "\tplt.xlabel('Epochs')\n",
    "\tplt.ylabel('Cost')\n",
    "\tplt.plot(num_epochs, J_all, 'm', linewidth = \"5\")\n",
    "\tplt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(theta, x):\n",
    "\tx[0] = (x[0] - mu[0])/std[0]\n",
    "\tx[1] = (x[1] - mu[1])/std[1]\n",
    "\n",
    "\ty = theta[0] + theta[1]*x[0] + theta[2]*x[1]\n",
    "\tprint(\"Price of house: \", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = load_data(\"data_set_name.txt\") # Data set to be Loaded.\n",
    "y = np.reshape(y, (46,1))\n",
    "x = np.hstack((np.ones((x.shape[0],1)), x))\n",
    "theta = np.zeros((x.shape[1], 1))\n",
    "learning_rate = 0.1\n",
    "num_epochs = 50\n",
    "theta, J_all = gradient_descent(x, y, theta, learning_rate, num_epochs)\n",
    "J = cost_function(x, y, theta)\n",
    "print(\"Cost: \", J)\n",
    "print(\"Parameters: \", theta)\n",
    "\n",
    "#for testing and plotting cost \n",
    "n_epochs = []\n",
    "jplot = []\n",
    "count = 0\n",
    "for i in J_all:\n",
    "\tjplot.append(i[0][0])\n",
    "\tn_epochs.append(count)\n",
    "\tcount += 1\n",
    "jplot = np.array(jplot)\n",
    "n_epochs = np.array(n_epochs)\n",
    "plot_cost(jplot, n_epochs)\n",
    "\n",
    "test(theta, [1600, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
